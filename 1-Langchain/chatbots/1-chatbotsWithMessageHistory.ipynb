{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # load all env variables\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f964cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001DE98C496A0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001DE98C4BA10>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model = \"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "975f3a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Deepak, it's nice to meet you! \\n\\nThat's a fascinating title. As a large language model, I'm always interested in learning more about the work of AI engineers.  \\n\\nWhat kind of projects are you working on?  What are some of the biggest challenges you face in your role?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 22, 'total_tokens': 91, 'completion_time': 0.125454545, 'prompt_time': 0.002178782, 'queue_time': 0.24771489100000002, 'total_time': 0.127633327}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--6a787cab-8d9c-40bf-a6c5-a5974dfa6bc1-0', usage_metadata={'input_tokens': 22, 'output_tokens': 69, 'total_tokens': 91})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Deepak.I am a chief AI engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c69103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Deepak, and you are a chief AI engineer.  ðŸ˜Š \\n\\nIs there anything else you'd like to tell me about yourself or your work? I'm eager to learn more! \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 111, 'total_tokens': 160, 'completion_time': 0.089090909, 'prompt_time': 0.00612799, 'queue_time': 0.322710649, 'total_time': 0.095218899}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--8be067a2-f921-48df-a2a4-25b314d534ca-0', usage_metadata={'input_tokens': 111, 'output_tokens': 49, 'total_tokens': 160})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "       HumanMessage(content=\"Hi, My name is Deepak.I am a chief AI engineer\"),\n",
    "       AIMessage(content=\"Hello Deepak, it's nice to meet you! \\n\\nThat's a fascinating title. As a large language model, I'm always interested in learning more about the work of AI engineers.  \\n\\nWhat kind of projects are you working on?  What are some of the biggest challenges you face in your role?\\n\"),\n",
    "       HumanMessage(content=\"Hey, What is my name and what do I do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75b3810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message History\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d41846d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ee733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Deepak! It's great to meet you.  \\n\\nBeing a Chief AI Engineer is a pretty awesome title! What kind of work do you do in that role? What are some of the most interesting projects you're working on?  \\n\\nI'm always fascinated to hear about the real-world applications of AI.  ðŸ˜Š  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 111, 'total_tokens': 184, 'completion_time': 0.132727273, 'prompt_time': 0.005646445, 'queue_time': 0.250953147, 'total_time': 0.138373718}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--e00fe3bd-9980-4572-87a9-f2324543d6d5-0', usage_metadata={'input_tokens': 111, 'output_tokens': 73, 'total_tokens': 184})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "\n",
    "    [HumanMessage(content=\"Hi, My name is Deepak.I am a chief AI engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11884b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Deepak! It's nice to meet you.\\n\\nAs a chief AI engineer, I imagine you have a fascinating and challenging role. What are some of the most exciting projects you're working on right now? \\n\\nI'm always eager to learn more about the advancements being made in the field of AI.\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ca3fb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You said your name is Deepak.  \\n\\nIs there anything else I can help you with?  \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "\n",
    "    [HumanMessage(content=\"Hi, What is my name\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c56b7d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I have no memory of past conversations and do not know your name. If you'd like to tell me your name, I'd be happy to know! ðŸ˜Š\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_2 = {\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "\n",
    "    [HumanMessage(content=\"Hi, What is my name\")],\n",
    "    config=config_2\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f92d0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi John, it's nice to meet you!  \\n\\nIs there anything I can help you with today?\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "\n",
    "    [HumanMessage(content=\"My name is John\")],\n",
    "    config=config_2\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63407aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is John!  I remember you telling me earlier.  ðŸ˜Š \\n\\nIs there anything else I can help you with, John?\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "\n",
    "    [HumanMessage(content=\"Hi, What is my name\")],\n",
    "    config=config_2\n",
    ")\n",
    "\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
